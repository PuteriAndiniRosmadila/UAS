{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtjnul/dzdToGTEwEz6lN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PuteriAndiniRosmadila/UAS/blob/main/UAS_Machine_Learning_Puteri_Andini_Rosmadila.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(x[1,1].item())\n",
        "\n",
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OeuGqG01c-_",
        "outputId": "ebfdf164-c280-4ba1-dfc0-1e4d1bfcb43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.2477e+28])\n",
            "tensor([-4.3053e+28,  4.5628e-41,  2.7990e-33])\n",
            "tensor([[-4.3053e+28,  4.5628e-41,  3.5588e-33],\n",
            "        [ 0.0000e+00,  4.4842e-44,  0.0000e+00]])\n",
            "tensor([[[2.7991e-33, 0.0000e+00, 1.4013e-45],\n",
            "         [0.0000e+00, 1.4013e-45, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n",
            "tensor([[0.5498, 0.1429, 0.4222],\n",
            "        [0.1496, 0.7654, 0.7474],\n",
            "        [0.4973, 0.7974, 0.2839],\n",
            "        [0.7559, 0.8471, 0.2635],\n",
            "        [0.4817, 0.6544, 0.3972]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "tensor([[0.8621, 0.0699, 0.8845],\n",
            "        [0.1141, 0.5350, 0.2037],\n",
            "        [0.4490, 0.7847, 0.3156],\n",
            "        [0.4897, 0.4721, 0.7604],\n",
            "        [0.2072, 0.1008, 0.8653]])\n",
            "tensor([0.8621, 0.1141, 0.4490, 0.4897, 0.2072])\n",
            "tensor([0.1141, 0.5350, 0.2037])\n",
            "tensor(0.5350)\n",
            "0.5349817872047424\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule\n",
        "\n",
        "# -------------\n",
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward()\n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# -------------\n",
        "# Stop a tensor from tracking history:\n",
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "# -------------\n",
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO6zgoNs1g9w",
        "outputId": "258ae0ff-0acb-48e8-87e2-ce3420cba165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0526, 0.4163, 0.0656], requires_grad=True)\n",
            "tensor([2.0526, 2.4163, 2.0656], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f31052664d0>\n",
            "tensor([12.6391, 17.5154, 12.8006], grad_fn=<MulBackward0>)\n",
            "tensor(14.3184, grad_fn=<MeanBackward0>)\n",
            "tensor([4.1051, 4.8326, 4.1313])\n",
            "tensor([-2833.1523,  2700.0110,  -993.4476], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n",
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7f31053077c0>\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()\n",
        "\n",
        "# next forward and backward pass..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIZ6yhLp1ksx",
        "outputId": "52227be5-6fd3-4281-f552-894d4e97748d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute every step manually\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# J = MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N * 2x(w*x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.mean(2*x*(y_pred - y))\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiQ4uoLB1sXE",
        "outputId": "d90a0cd9-fe68-411a-f18a-1d4558b0c76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 3: w = 0.772, loss = 15.66018677\n",
            "epoch 5: w = 1.113, loss = 8.17471600\n",
            "epoch 7: w = 1.359, loss = 4.26725292\n",
            "epoch 9: w = 1.537, loss = 2.22753215\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 13: w = 1.758, loss = 0.60698175\n",
            "epoch 15: w = 1.825, loss = 0.31684822\n",
            "epoch 17: w = 1.874, loss = 0.16539653\n",
            "epoch 19: w = 1.909, loss = 0.08633806\n",
            "Prediction after training: f(5) = 9.612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvB-Pqlx1v5b",
        "outputId": "634d1328-7679-47a7-ffc2-2ab9606ad3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvfCatyb1y0m",
        "outputId": "124862b9-d93e-4dcb-a5b6-ce852255a038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = 0.067\n",
            "epoch  1 : w =  0.3807602524757385  loss =  tensor(30.8789, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.6560859680175781  loss =  tensor(0.8130, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.863685965538025  loss =  tensor(0.0343, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.8994708061218262  loss =  tensor(0.0134, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.9075485467910767  loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.911101222038269  loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.913859248161316  loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.9164249897003174  loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.918897271156311  loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.9212934970855713  loss =  tensor(0.0090, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model (input, output, forward pass with different layers)\n",
        "# 2) Construct loss and optimizer\n",
        "# 3) Training loop\n",
        "#       - Forward = compute prediction and loss\n",
        "#       - Backward = compute gradients\n",
        "#       - Update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L3HMEpw112E",
        "outputId": "30df0ba5-83ea-493a-c705-7d20e6602c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = 4.414\n",
            "epoch  1 : w =  0.9917606711387634  loss =  tensor(8.7856, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.6742428541183472  loss =  tensor(0.2816, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.7888514995574951  loss =  tensor(0.0584, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.811975359916687  loss =  tensor(0.0497, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.8202457427978516  loss =  tensor(0.0467, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.825992465019226  loss =  tensor(0.0439, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.8312026262283325  loss =  tensor(0.0414, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.8362001180648804  loss =  tensor(0.0390, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.8410403728485107  loss =  tensor(0.0367, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.8457362651824951  loss =  tensor(0.0346, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "Xo-omLXS15CY",
        "outputId": "1bdb5023-2236-4ecd-83a5-9b53647738e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4024.3948\n",
            "epoch: 20, loss = 2836.7063\n",
            "epoch: 30, loss = 2027.1239\n",
            "epoch: 40, loss = 1475.1577\n",
            "epoch: 50, loss = 1098.7523\n",
            "epoch: 60, loss = 842.0154\n",
            "epoch: 70, loss = 666.8660\n",
            "epoch: 80, loss = 547.3532\n",
            "epoch: 90, loss = 465.7885\n",
            "epoch: 100, loss = 410.1116\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ynu63zH18vo",
        "outputId": "56e89472-7197-405b-a2ae-0be044198a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.7393\n",
            "epoch: 20, loss = 0.5614\n",
            "epoch: 30, loss = 0.4597\n",
            "epoch: 40, loss = 0.3953\n",
            "epoch: 50, loss = 0.3508\n",
            "epoch: 60, loss = 0.3183\n",
            "epoch: 70, loss = 0.2933\n",
            "epoch: 80, loss = 0.2734\n",
            "epoch: 90, loss = 0.2572\n",
            "epoch: 100, loss = 0.2436\n",
            "accuracy: 0.9035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# gradient computation etc. not efficient for whole data set\n",
        "# -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "'''\n",
        "\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass\n",
        "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
        "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
        "\n",
        "# --> DataLoader can do the batch computation for us\n",
        "\n",
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "\n",
        "# some famous datasets are available in torchvision.datasets\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=3,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "mXnJ7rcI1_wf",
        "outputId": "d30c6dfa-54a9-4159-99a8-876eb7bee65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-edd5d33ad7c2>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# create dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# get first sample and unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-edd5d33ad7c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Initialize data, download, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# read with numpy or pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/wine/wine.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: ./data/wine/wine.csv not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
        "during creation of the DataSet\n",
        "\n",
        "complete list of built-in transforms:\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "On Images\n",
        "---------\n",
        "CenterCrop, Grayscale, Pad, RandomAffine\n",
        "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
        "Resize, Scale\n",
        "\n",
        "On Tensors\n",
        "----------\n",
        "LinearTransformation, Normalize, RandomErasing\n",
        "\n",
        "Conversion\n",
        "----------\n",
        "ToPILImage: from tensor or ndrarray\n",
        "ToTensor : from numpy.ndarray or PILImage\n",
        "\n",
        "Generic\n",
        "-------\n",
        "Use Lambda\n",
        "\n",
        "Custom\n",
        "------\n",
        "Write own class\n",
        "\n",
        "Compose multiple Transforms\n",
        "---------------------------\n",
        "composed = transforms.Compose([Rescale(256),\n",
        "                               RandomCrop(224)])\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)"
      ],
      "metadata": {
        "id": "oPP-ck5Y2DCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "#\n",
        "#        -> 2.0              -> 0.65\n",
        "# Linear -> 1.0  -> Softmax  -> 0.25   -> CrossEntropy(y, y_hat)\n",
        "#        -> 0.1              -> 0.1\n",
        "#\n",
        "#     scores(logits)      probabilities\n",
        "#                           sum = 1.0\n",
        "#\n",
        "\n",
        "# Softmax applies the exponential function to each element, and normalizes\n",
        "# by dividing by the sum of all these exponentials\n",
        "# -> squashes the output to be between 0 and 1 = probability\n",
        "# sum of all probabilities is 1\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)\n",
        "\n"
      ],
      "metadata": {
        "id": "LllmWk422F9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "har6bK122Nsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##### Sigmoid\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,100)\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(y,sigmoid(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Sigmoid Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-2, -1, 0, 1, 2])\n",
        "\n",
        "plt.ylim(-2, 2)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('sigmoid.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "##### TanH\n",
        "tanh = lambda x: 2*sigmoid(2*x)-1\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,100)\n",
        "\n",
        "plt.plot(y,tanh(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('TanH Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('tanh.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "##### ReLU\n",
        "relu = lambda x: np.where(x>=0, x, 0)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,relu(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('ReLU')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('relu.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "##### Leaky ReLU\n",
        "leakyrelu = lambda x: np.where(x>=0, x, 0.1*x)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,leakyrelu(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Leaky ReLU')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "\n",
        "plt.ylim(-4, 4)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('lrelu.png')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "\n",
        "##### Binary Step\n",
        "bstep = lambda x: np.where(x>=0, 1, 0)\n",
        "\n",
        "x=np.linspace(-10,10,10)\n",
        "\n",
        "y=np.linspace(-10,10,1000)\n",
        "\n",
        "plt.plot(y,bstep(y),'b', label='linspace(-10,10,100)')\n",
        "\n",
        "plt.grid(linestyle='--')\n",
        "\n",
        "plt.xlabel('X Axis')\n",
        "\n",
        "plt.ylabel('Y Axis')\n",
        "\n",
        "plt.title('Step Function')\n",
        "\n",
        "plt.xticks([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
        "plt.yticks([-2, -1, 0, 1, 2])\n",
        "\n",
        "plt.ylim(-2, 2)\n",
        "plt.xlim(-4, 4)\n",
        "\n",
        "plt.show()\n",
        "#plt.savefig('step.png')\n",
        "\n",
        "print('done')"
      ],
      "metadata": {
        "id": "8j5h-ARa2OXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "id": "P_11-Xib2Rfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "metadata": {
        "id": "V4SJB36Z2UBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "#### Finetuning the convnet ####\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# Learning rate scheduling should be applied after optimizer’s update\n",
        "# e.g., you should write your code this way:\n",
        "# for epoch in range(100):\n",
        "#     train(...)\n",
        "#     validate(...)\n",
        "#     scheduler.step()\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "# Here, we need to freeze all the network except the final layer.\n",
        "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "id": "BlFoENlf2Wki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n",
        "    ###################################################"
      ],
      "metadata": {
        "id": "f0qPomBf2ZEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "''' 3 DIFFERENT METHODS TO REMEMBER:\n",
        " - torch.save(arg, PATH) # can be model, tensor, or dictionary\n",
        " - torch.load(PATH)\n",
        " - torch.load_state_dict(arg)\n",
        "'''\n",
        "\n",
        "''' 2 DIFFERENT WAYS OF SAVING\n",
        "# 1) lazy way: save whole model\n",
        "torch.save(model, PATH)\n",
        "\n",
        "# model class must be defined somewhere\n",
        "model = torch.load(PATH)\n",
        "model.eval()\n",
        "\n",
        "# 2) recommended way: save only the state_dict\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# model must be created again with parameters\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "'''\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# train your model...\n",
        "\n",
        "####################save all ######################################\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# save and load entire model\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "############save only state dict #########################\n",
        "\n",
        "# save only state dict\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "###########load checkpoint#####################\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 90,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "# Remember that you must call model.eval() to set dropout and batch normalization layers\n",
        "# to evaluation mode before running inference. Failing to do this will yield\n",
        "# inconsistent inference results. If you wish to resuming training,\n",
        "# call model.train() to ensure these layers are in training mode.\n",
        "\n",
        "\"\"\" SAVING ON GPU/CPU\n",
        "\n",
        "# 1) Save on GPU, Load on CPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "\n",
        "# 2) Save on GPU, Load on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "\n",
        "# Note: Be sure to use the .to(torch.device('cuda')) function\n",
        "# on all model inputs, too!\n",
        "\n",
        "# 3) Save on CPU, Load on GPU\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n",
        "model.to(device)\n",
        "\n",
        "# This loads the model to a given GPU device.\n",
        "# Next, be sure to call model.to(torch.device('cuda')) to convert the model’s parameter tensors to CUDA tensors\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Z5knA9AY2bwe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}